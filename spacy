import spacy 

a = spacy.load('en')
sentence = "Be extremely subtle, even to the point of formlessness. Be extremely mysterious, even to the point of soundlessness. Thereby you can be the director of the opponent's fate." 
doc = a(sentence) 
word_tokenized_sentence = [token.text for token in doc] 

print(word_tokenized_sentence)

